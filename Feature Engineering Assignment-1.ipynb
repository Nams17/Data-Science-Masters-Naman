{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430096e8-799c-4f2c-8874-c1e3e3283aa6",
   "metadata": {},
   "source": [
    "# Q-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccdbb6-27b6-4e16-995d-6d90596a90ee",
   "metadata": {},
   "source": [
    "### Missing values in a dataset refer to the absence of data in certain observations or variables. These missing values can arise due to various reasons such as data entry errors, equipment failures, or participants choosing not to provide certain information.\n",
    "### Missing values in a dataset refer to the absence of data in certain observations or variables. These missing values can arise due to various reasons such as data entry errors, equipment failures, or participants choosing not to provide certain information.\n",
    "### Some algorithms that are not affected by missing values are:\n",
    "### Random Forest\n",
    "### Decision Trees\n",
    "### Gradient boosting machines\n",
    "### Principle component analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ccda3-af3c-48ac-ab54-249cbe6dab3d",
   "metadata": {},
   "source": [
    "# Q-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfa2d4-a90d-45ac-a3d7-4769caf6a871",
   "metadata": {},
   "source": [
    "### There are several techniques that can be used to handle missing data, some of which are:\n",
    "### Deletion: In this technique, missing values are removed from the dataset. There are two types of deletion:\n",
    "### Listwise Deletion: This technique removes entire rows that contain missing values.\n",
    "### Pairwise Deletion: This technique removes only the missing values from the calculation of a particular statistic, such as mean or correlation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab4ff7-797e-4c68-a052-ab766109c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of pairwise deletion in Python using the pandas library:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Reading in the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Dropping missing values for a particular variable\n",
    "df['variable_name'].dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5ec7c-86c4-4dd9-b743-34509476e43f",
   "metadata": {},
   "source": [
    "### Mean/Mode/Median Imputation: In this technique, missing values are replaced with the mean, mode, or median of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943e77d-ee68-4569-a1b0-c48eb23de9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of mean imputation in Python using the pandas library:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Reading in the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Calculating the mean of a particular variable\n",
    "mean = df['variable_name'].mean()\n",
    "\n",
    "# Imputing missing values with mean\n",
    "df['variable_name'].fillna(mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4774ee-2844-4cb9-8122-38298e891323",
   "metadata": {},
   "source": [
    "### Regression Imputation: In this technique, missing values are imputed using regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad856ec-cdb8-4130-ac45-747d01a315fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of regression imputation in Python using the scikit-learn library:\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Reading in the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Creating a regression imputer object\n",
    "reg_imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Fitting the regression imputer object on the dataset\n",
    "reg_imp.fit(df[['independent_variable_1', 'independent_variable_2']])\n",
    "\n",
    "# Imputing missing values\n",
    "df[['independent_variable_1', 'independent_variable_2']] = reg_imp.transform(df[['independent_variable_1', 'independent_variable_2']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa7b2e-9e62-4d69-8585-0a2618b6ce33",
   "metadata": {},
   "source": [
    "# Q-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8936ca-536a-4349-b0bc-2cda568d65e3",
   "metadata": {},
   "source": [
    "### Imbalanced data is a situation where the classes or categories in the data are not represented equally. In other words, one class has significantly fewer observations than the other classes. For instance, in a binary classification problem, if 90% of the data belongs to one class and only 10% to the other, then the data is imbalanced.\n",
    "### If imbalanced data is not handled, the machine learning algorithm may become biased towards the majority class, leading to a low accuracy of the model. This is because the model tends to predict the majority class more often, and hence, the minority class is not well predicted, leading to a lower recall rate. In some cases, the model may even classify all instances to the majority class, which is of no use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026021e9-30a6-4d94-a0fa-e981f77992e5",
   "metadata": {},
   "source": [
    "# Q-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894dbed-93e0-4f52-8491-a6ddc7d8b6b9",
   "metadata": {},
   "source": [
    "### Up-sampling and down-sampling are two techniques used to handle imbalanced data.\n",
    "\n",
    "### Up-sampling involves increasing the number of instances in the minority class to balance the data. This can be achieved by duplicating the minority class observations or creating new synthetic data points based on the existing minority class instances.\n",
    "### Down-sampling, on the other hand, involves decreasing the number of instances in the majority class to balance the data. This can be achieved by randomly removing instances from the majority class or by selecting a subset of the majority class instances.\n",
    "### An example when up-sampling is required is in fraud detection, where the number of fraudulent transactions is very low compared to the number of legitimate transactions. In this case, the minority class (fraudulent transactions) can be up-sampled to balance the data.\n",
    "### An example when down-sampling is required is in medical diagnosis, where the number of healthy patients is much higher than the number of patients with a disease. In this case, the majority class (healthy patients) can be down-sampled to balance the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd1e304-e527-485e-9c17-7e765f61fa48",
   "metadata": {},
   "source": [
    "# Q-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f9626-e602-44be-ad33-eba861674657",
   "metadata": {},
   "source": [
    "### Data augmentation is a technique used to artificially increase the size of a dataset by creating new, synthetic data points. This is typically done by applying various transformations to the original data points, such as flipping, rotating, scaling, and adding noise.\n",
    "### SMOTE (Synthetic Minority Over-sampling Technique) is a popular data augmentation technique used to handle imbalanced data. It involves creating synthetic examples of the minority class by interpolating between existing minority class instances. Specifically, SMOTE selects a minority class instance and finds its k nearest neighbors. Then, for each selected neighbor, SMOTE creates a synthetic data point by randomly selecting a point along the line segment that connects the selected instance and its neighbor. The synthetic data points generated by SMOTE are then added to the original dataset, resulting in a balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9034d4d0-cae3-431e-a743-91c330045954",
   "metadata": {},
   "source": [
    "# Q-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c941501-e624-4be2-ab3a-cce030eb24ff",
   "metadata": {},
   "source": [
    "### Outliers are data points that are significantly different from other data points in a dataset. They can be identified as extreme values that are either much higher or much lower than the other data points in the dataset.\n",
    "### It is essential to handle outliers for several reasons:\n",
    "### 1. They can significantly affect the accuracy of the statistical models. The presence of outliers can skew the distribution of the data and lead to inaccurate estimates of the mean, variance, and other statistical measures.\n",
    "### 2. Outliers can also have a significant impact on machine learning models. They can lead to overfitting, where the model becomes too complex and captures the noise in the data instead of the underlying patterns.\n",
    "### 3. Outliers can also reduce the efficiency of some algorithms, such as clustering algorithms, which group similar data points together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b16b1-314a-4f3c-b889-bdd70f0c8522",
   "metadata": {},
   "source": [
    "# Q-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f07b56-9f80-489a-b49f-ab17074d4bbd",
   "metadata": {},
   "source": [
    "### There are several techniques that can be used to handle missing data in customer data analysis:\n",
    "### 1. Deletion\n",
    "### 2. Mean/Median/Mode Imputation\n",
    "### 3. Multiple Imputation\n",
    "### 4. Regression Imputation\n",
    "### 5. K-nearest neighbors imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba83996-a94a-48fe-b1ff-2147f7b32dd3",
   "metadata": {},
   "source": [
    "# Q-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e68aa-e795-4ef5-be12-7c5d2a446760",
   "metadata": {},
   "source": [
    "### There are several strategies that can be used to determine if the missing data is missing at random or if there is a pattern to the missing data:\n",
    "### 1.Visualizations: Creating visualizations such as histograms or scatter plots can help identify if there is a pattern to the missing data. For example, if there is a relationship between the missing data and another variable, it may be visible in a scatter plot.\n",
    "### 2.Descriptive statistics: Calculating summary statistics such as mean, median, or mode for the variables with missing data can help identify if the missing data is missing at random. If the mean or median of the variable with missing data is similar to the mean or median of the variable without missing data, then it may be missing at random.\n",
    "### 3.Correlation analysis: Conducting a correlation analysis between the variables with missing data and the variables without missing data can help identify if there is a pattern to the missing data. If there is a significant correlation between the variables with missing data and the variables without missing data, it may suggest a pattern to the missing data.\n",
    "### 4.Missing data tests: There are several statistical tests, such as the Little's MCAR test, that can be used to determine if the missing data is missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR).\n",
    "### 5.Imputation methods: Imputation methods can also be used to identify if there is a pattern to the missing data. For example, if regression imputation is used and the missing data is significantly predicted by other variables in the dataset, it may suggest a pattern to the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34430ba2-bd69-4c8e-a2cb-91b10968ecf7",
   "metadata": {},
   "source": [
    "# Q-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c345d-5e33-4fb7-a293-6906f3493834",
   "metadata": {},
   "source": [
    "### Resampling techniques: Resampling techniques such as oversampling and undersampling can be used to balance the class distribution in the dataset. Oversampling involves adding more examples of the minority class, while undersampling involves removing examples from the majority class. These techniques can help improve the performance of machine learning models on imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d398f2-09c2-4dce-ba97-2a6b8fe3d90c",
   "metadata": {},
   "source": [
    "# Q-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac485b-6b52-4d1d-ba1a-8e05f319ebb2",
   "metadata": {},
   "source": [
    "### Random under-sampling: Randomly selecting a subset of the majority class data points to match the number of minority class data points. This method is quick and easy to implement but can result in loss of information and might not represent the actual data distribution.\n",
    "### Random over-sampling: Randomly replicating the minority class data points to match the number of majority class data points. This method can result in overfitting and can lead to incorrect results.\n",
    "### Synthetic Minority Over-sampling Technique (SMOTE): This method creates synthetic samples by interpolating between the minority class samples. SMOTE is widely used in data science and machine learning to handle imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303e0a2-e5cd-4be6-a9a8-626c71c826fc",
   "metadata": {},
   "source": [
    "# Q-11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0bf41-7e5b-4603-8231-cb27147fc4bd",
   "metadata": {},
   "source": [
    "### When dealing with imbalanced datasets where the minority class has a low percentage of occurrences, one commonly used technique is up-sampling. Up-sampling refers to the process of creating more examples of the minority class to balance the dataset. There are different methods for up-sampling, but one popular method is Synthetic Minority Over-sampling Technique (SMOTE).\n",
    "\n",
    "### SMOTE creates synthetic examples of the minority class by interpolating between existing examples. The basic idea is to identify the k-nearest neighbors of each minority class example and create synthetic examples along the line segments between them. This increases the number of minority class examples and helps to balance the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fe2b7-8a24-4389-ac6c-4d748a02bea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
